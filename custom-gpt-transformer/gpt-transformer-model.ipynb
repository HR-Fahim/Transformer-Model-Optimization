{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac952fd",
   "metadata": {},
   "source": [
    "#### Torch Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e26f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693cc813",
   "metadata": {},
   "source": [
    "#### CUDA Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c84dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd7bd7",
   "metadata": {},
   "source": [
    "#### Hyperperameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1253e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "block_size = 64\n",
    "n_layer = 4 \n",
    "n_head = 8\n",
    "n_embd = 256\n",
    "\n",
    "print(n_embd // n_head) # Test purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27eed6",
   "metadata": {},
   "source": [
    "#### Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8a7dcf-c82f-4f76-8625-01974fb32265",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = \"\"\n",
    "\n",
    "# Read the contents of the file 'infinite_in_modern_thought.txt' and store it in the variable 'text'\n",
    "with open('infinite_in_modern_thought.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Print the first 1000 characters of the text\n",
    "# print(text[:1000])\n",
    "\n",
    "# Create a list of unique characters in the text and sort them\n",
    "chars = sorted(list(set(text)))\n",
    "# print(chars)\n",
    "\n",
    "# Print the number of unique characters\n",
    "# print(len(chars))\n",
    "\n",
    "# print(text[:1000])\n",
    "chars = sorted(list(set(text)))\n",
    "# print(chars)\n",
    "# print(len(chars))\n",
    "\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922e2a5",
   "metadata": {},
   "source": [
    "#### Simple Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569fea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 61, 68, 68, 71, 11, 1, 50, 71, 74, 68, 60, 2]\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that maps each character to its index in the 'chars' list\n",
    "string_to_index = {ch: i for i, ch in enumerate(chars)}\n",
    "\n",
    "# Create a dictionary that maps each index to its corresponding character in the 'chars' list\n",
    "index_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Define the 'endcode' function that converts a string to a list of character indices\n",
    "endcode = lambda s: [string_to_index[c] for c in s]\n",
    "\n",
    "# Define the 'decode' function that converts a list of character indices to a string\n",
    "decode = lambda l: ''.join([index_to_string[i] for i in l])\n",
    "\n",
    "print(endcode(\"Hello, World!\"))\n",
    "\n",
    "print(decode(endcode(\"Hello, World!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674aee3",
   "metadata": {},
   "source": [
    "#### Torch Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99153e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65, 76, 61,  1, 65, 70,  1, 69, 71, 60, 61, 74, 70,  1,\n",
      "        76, 64, 71, 77, 63, 64, 76,  0,  1,  1,  1,  1,  0, 47, 64, 65, 75,  1,\n",
      "        61, 58, 71, 71, 67,  1, 65, 75,  1, 62])\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that maps each character to its index in the 'chars' list\n",
    "string_to_index = {ch: i for i, ch in enumerate(chars)}\n",
    "\n",
    "# Create a dictionary that maps each index to its corresponding character in the 'chars' list\n",
    "index_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Define the 'endcode' function that converts a string to a list of character indices\n",
    "endcode = lambda s: [string_to_index[c] for c in s]\n",
    "\n",
    "# Define the 'decode' function that converts a list of character indices to a string\n",
    "decode = lambda l: ''.join([index_to_string[i] for i in l])\n",
    "\n",
    "# Create a tensor from the encoded text using torch.tensor\n",
    "data = torch.tensor(endcode(text), dtype=torch.long)\n",
    "\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_chunk(split):\n",
    "#     data = train_data if split == 'train' else val_data\n",
    "#     with open(data, 'rb') as f:\n",
    "#         with map.map(f.fileno(), 0, access=map.ACCESS_READ) as m:\n",
    "#             file_size = len(m)\n",
    "#             start_idx = random.randint(0, file_size - block_size*batch_size)\n",
    "#             m.seek(start_idx)\n",
    "#             block = m.read(block_size*batch_size)\n",
    "#             decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "#             data = torch.tensor(endcode(decoded_block), dtype=torch.long)\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# def get_batch(split):\n",
    "#     data = get_random_chunk(split)\n",
    "#     ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "#     x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "#     y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ebb88",
   "metadata": {},
   "source": [
    "#### Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33186e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets\n",
    "data_size = int(0.9 * len(data))  # Calculate the size of the train data\n",
    "\n",
    "train_data = data[:data_size]  # Assign the first 90% of the data to the train_data variable\n",
    "val_data = data[data_size:]  # Assign the remaining 10% of the data to the val_data variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0aca5f",
   "metadata": {},
   "source": [
    "#### Tensor Process Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97864467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([97]), the target: 47\n",
      "when input is tensor([97, 47]), the target: 64\n",
      "when input is tensor([97, 47, 64]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1]), the target: 43\n",
      "when input is tensor([97, 47, 64, 61,  1, 43]), the target: 74\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74]), the target: 71\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71]), the target: 66\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61]), the target: 59\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59]), the target: 76\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1]), the target: 34\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34]), the target: 77\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77]), the target: 76\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61]), the target: 70\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70]), the target: 58\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61]), the target: 74\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74]), the target: 63\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61]), the target: 29\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29]), the target: 71\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71]), the target: 71\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71]), the target: 67\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1]), the target: 71\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71]), the target: 62\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1]), the target: 42\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42]), the target: 70\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1]), the target: 76\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76]), the target: 64\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1]), the target: 76\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76]), the target: 64\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61]), the target: 71\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71]), the target: 74\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74]), the target: 81\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1]), the target: 71\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71]), the target: 62\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1]), the target: 76\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76]), the target: 64\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1]), the target: 65\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65]), the target: 70\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70]), the target: 62\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62]), the target: 65\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65]), the target: 70\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70]), the target: 65\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65]), the target: 76\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65, 76]), the target: 61\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65, 76, 61]), the target: 1\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65, 76, 61,  1]), the target: 65\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65, 76, 61,  1, 65]), the target: 70\n",
      "when input is tensor([97, 47, 64, 61,  1, 43, 74, 71, 66, 61, 59, 76,  1, 34, 77, 76, 61, 70,\n",
      "        58, 61, 74, 63,  1, 61, 29, 71, 71, 67,  1, 71, 62,  1, 42, 70,  1, 76,\n",
      "        64, 61,  1, 76, 64, 61, 71, 74, 81,  1, 71, 62,  1, 76, 64, 61,  1, 65,\n",
      "        70, 62, 65, 70, 65, 76, 61,  1, 65, 70]), the target: 1\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    # Get the context by slicing the input sequence up to the current position\n",
    "    context = x[:t + 1]\n",
    "    \n",
    "    # Get the target by selecting the next character in the input sequence\n",
    "    target = y[t]\n",
    "    \n",
    "    # Print the context and target\n",
    "    print(f\"when input is {context}, the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248bc77",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc93cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64]) torch.Size([128, 64])\n",
      "tensor([[ 1, 75, 77,  ..., 69, 71, 74],\n",
      "        [62, 65, 74,  ..., 60, 60, 65],\n",
      "        [ 1, 57,  1,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [76,  1, 65,  ..., 76, 75,  1],\n",
      "        [60, 65, 69,  ..., 59, 71, 77],\n",
      "        [ 1, 36, 70,  ..., 76, 64, 61]], device='cuda:0')\n",
      "tensor([[75, 77, 59,  ..., 71, 74, 61],\n",
      "        [65, 74, 75,  ..., 60, 65, 70],\n",
      "        [57,  1, 62,  ...,  1,  1, 81],\n",
      "        ...,\n",
      "        [ 1, 65, 62,  ..., 75,  1, 62],\n",
      "        [65, 69, 61,  ..., 71, 77, 74],\n",
      "        [36, 70, 62,  ..., 64, 61, 69]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and validation sets\n",
    "data_size = int(0.9 * len(data))  # Calculate the size of the train data\n",
    "\n",
    "train_data = data[:data_size]  # Assign the first 90% of the data to the train_data variable\n",
    "val_data = data[data_size:]  # Assign the remaining 10% of the data to the val_data variable\n",
    "\n",
    "# Define the get_batch function that returns a batch of data\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Get a batch of training data\n",
    "x, y = get_batch('train')\n",
    "\n",
    "# Print the shape of x and y\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# Print the values of x and y\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee42a2",
   "metadata": {},
   "source": [
    "#### Bigram (Autoregressive Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2e5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\"One head of self-attention.\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch, time-step, channels)\n",
    "        # Output shape: (batch, time-step, head size)\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B, T, hs)\n",
    "        q = self.query(x) # (B, T, hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # (B, T, hs) @ (B, T, T) -> (B, hs, T)\n",
    "        v = self.value(x) # (B, T, hs)\n",
    "        out = wei @ v # (B, T, hs)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727e9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention layer.\"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Head(head_size) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.proj = nn.Linear(head_size * head_size, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B,T, F) -> (B,T, (h1, h1, h2, h2, h3, h3, h4, h4))\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c4b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b25c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Block(nn.Module):\n",
    "#     \"\"\"Transformer block: A multi-head attention layer followed by a feedforward layer.\"\"\"\n",
    "\n",
    "#     def __init__(self, n_embd, n_head):\n",
    "#         # n_embd is the embedding dimension, n_head is the number of attention heads\n",
    "#         # n_head is the number of attention heads\n",
    "\n",
    "#         super().__init__()\n",
    "#         head_size = n_embd // n_head\n",
    "#         self.sa = nn.MultiheadAttention(embed_dim=n_embd, num_heads=n_head)\n",
    "\n",
    "#         # self.ffn = nn.Sequential(\n",
    "#         #     nn.Linear(n_embd, 4 * n_embd),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.Linear(4 * n_embd, n_embd),\n",
    "#         # )\n",
    "\n",
    "#         self.ffw = FeedForward(n_embd)\n",
    "#         self.ln1 = nn.LayerNorm(n_embd)\n",
    "#         self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Transpose for compatibility with nn.MultiheadAttention\n",
    "#         x = x.transpose(0, 1)  # (T, B, C) for MultiheadAttention\n",
    "#         y, _ = self.sa(x, x, x)  # Pass x as query, key, and value\n",
    "#         x = x + y  # Residual connection\n",
    "#         x = self.ln1(x)\n",
    "#         x = x.transpose(0, 1)  # Back to (B, T, C)\n",
    "#         y = self.ffw(x)\n",
    "#         x = x + y  # Residual connection\n",
    "#         x = self.ln2(x)\n",
    "#         return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: A multi-head attention layer followed by a feedforward layer.\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd is the embedding dimension, n_head is the number of attention heads\n",
    "        # n_head is the number of attention heads\n",
    "\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = nn.MultiheadAttention(n_embd, head_size)\n",
    "\n",
    "        # self.ffn = nn.Sequential(\n",
    "        #     nn.Linear(n_embd, 4 * n_embd),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(4 * n_embd, n_embd),\n",
    "        # )\n",
    "\n",
    "        self.ffw = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transpose for compatibility with nn.MultiheadAttention\n",
    "        x = x.transpose(0, 1)  # (T, B, C) for MultiheadAttention\n",
    "        y, _ = self.sa(x, x, x)  # Pass x as query, key, and value\n",
    "        x = x + y  # Residual connection\n",
    "        x = self.ln1(x)\n",
    "        x = x.transpose(0, 1)  # Back to (B, T, C)\n",
    "        y = self.ffw(x)\n",
    "        x = x + y  # Residual connection\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3ebc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    # Initialize the model with the vocabulary size\n",
    "    def __init__(self, vocab_size):\n",
    "        # Call the parent class's constructor\n",
    "        super().__init__()\n",
    "        # Create an embedding table to map token indices to vectors\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        # Create a multi-head attention layer (GPU/CPU)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embd, n_head=n_head)\n",
    "              for _ in range(n_layer)]\n",
    "        )\n",
    "\n",
    "        self.lm_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self.__init_weights)\n",
    "\n",
    "    def __init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    # Define the forward pass\n",
    "    def forward(self, idx, targets=None):\n",
    "        # Get the logits (unnormalized probabilities) for the input indices\n",
    "        # logits = self.token_embedding_table(idx).to(device)\n",
    "\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.lm_f(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        # If targets are not provided, set the loss to None\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        # If targets are provided, calculate the cross-entropy loss\n",
    "        else:\n",
    "            # Get the shape of the logits tensor (batch size, sequence length, vocab size)\n",
    "            B, T, C = logits.shape\n",
    "            # Reshape the logits tensor to (batch size * sequence length, vocab size)\n",
    "            logits = logits.view(B*T, C)\n",
    "            # Reshape the targets tensor to (batch size * sequence length)\n",
    "            targets = targets.view(B*T)\n",
    "            # Calculate the cross-entropy loss\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # Return the logits and loss\n",
    "        return logits, loss\n",
    "\n",
    "    # Define the generate method\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # Generate new tokens one at a time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get the logits and loss for the current input indices\n",
    "            logits, loss = self.forward(idx)\n",
    "            # Get the logits for the last token in the sequence\n",
    "            logits = logits[:, -1, :]\n",
    "            # Convert the logits to probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # Sample the next token from the probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # Append the next token to the current sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        # Return the generated sequence\n",
    "        return idx\n",
    "    \n",
    "model = GPTLanguageModel(vocab_size).to(device)\n",
    "\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad24d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.6516, val loss 4.6249\n",
      "3.3080713748931885\n"
     ]
    }
   ],
   "source": [
    "max_iter = 10\n",
    "learning_rate = 3e-4\n",
    "\n",
    "eval_interval = 100\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_interval)  # Initialize a tensor to store the losses\n",
    "        for i in range(eval_interval):\n",
    "            x, y = get_batch(split)  # Get a batch of data\n",
    "            T = x.shape[1]  # Define the variable 'T' as the sequence length\n",
    "            logits, loss = model(x, y)  # Forward pass through the model\n",
    "            losses[i] = loss.item()  # Store the loss value\n",
    "        out[split] = losses.mean()  # Calculate the mean loss for the split\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return out\n",
    "\n",
    "\n",
    "for iter in range(max_iter):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    # Get a batch of training data\n",
    "    x, y = get_batch('train')\n",
    "    # Get the logits and loss\n",
    "    logits, loss = model(x, y)\n",
    "    # Backpropagate the loss\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Print the loss every 100 iterations\n",
    "    # if iter % 100 == 0:\n",
    "    #     print(f\"loss: {loss.item()}\")\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b42836",
   "metadata": {},
   "source": [
    "#### Some Optimization Algorithms and Loss Functions\n",
    "\n",
    "**MSE (Mean Squared Error):** MSE is a commonly used loss function in regression problems. It measures the average squared difference between the predicted and actual values. The lower the MSE, the better the model's performance.\n",
    "\n",
    "**GD (Gradient Descent):** GD is an optimization algorithm used to minimize the loss function of a model. It iteratively updates the model's parameters in the direction of steepest descent of the loss function. GD can be slow for large datasets as it requires computing the gradients for the entire dataset in each iteration.\n",
    "\n",
    "**Momentum:** Momentum is an extension of GD that helps accelerate convergence and overcome local minima. It introduces a momentum term that accumulates the gradients of previous iterations and uses it to update the model's parameters. This helps the model to continue moving in the right direction even when the gradients are small.\n",
    "\n",
    "**RMSprop (Root Mean Square Propagation):** RMSprop is an optimization algorithm that adapts the learning rate for each parameter based on the average of recent squared gradients. It helps to speed up convergence by reducing the learning rate for parameters with large gradients and increasing it for parameters with small gradients.\n",
    "\n",
    "**Adam:** Adam (Adaptive Moment Estimation) is an optimization algorithm that combines the benefits of both momentum and RMSprop. It maintains a running average of both the gradients and the squared gradients, and uses them to update the model's parameters. Adam is known for its fast convergence and good performance on a wide range of problems.\n",
    "\n",
    "**AdamW:** AdamW is a variant of the Adam optimizer that incorporates weight decay regularization. Weight decay helps prevent overfitting by adding a penalty term to the loss function that discourages large parameter values. AdamW is particularly effective when dealing with models with large numbers of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40251cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_LAUNCH_BLOCKING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a context tensor with a single token (index 0)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# context = torch.zeros((1, 1), dtype=torch.long, device=device)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate a sequence of 100 tokens starting from the context\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m generated_chars \u001b[38;5;241m=\u001b[39m decode(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print the generated sequence\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_chars)\n",
      "Cell \u001b[1;32mIn[14], line 64\u001b[0m, in \u001b[0;36mGPTLanguageModel.generate\u001b[1;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[0;32m     61\u001b[0m device \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# Ensure we are using the same device as the input tensor\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Get logits and loss for current input\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure idx is on the correct device\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Get the logits for the last token in the sequence\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# (Batch_size, vocab_size)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 34\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Get the logits (unnormalized probabilities) for the input indices\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# logits = self.token_embedding_table(idx)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# idx and targets are both (B, T) tensor of integers\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(idx) \u001b[38;5;66;03m# (B, T, C)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# # Create a context tensor with a single token (index 0)\n",
    "# # context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "\n",
    "# # Generate a sequence of 100 tokens starting from the context\n",
    "# generated_chars = decode(m.generate(context, max_new_tokens=100)[0].tolist())\n",
    "# # Print the generated sequence\n",
    "# print(generated_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc13008",
   "metadata": {},
   "source": [
    "#### Block Size and Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "- The block size determines the size of each block in the tensor.\n",
    "- The batch size determines the number of blocks to be processed in parallel.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
